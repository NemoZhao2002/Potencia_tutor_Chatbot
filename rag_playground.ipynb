{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting global variables(OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: docx2txt in /Users/zjh/micromamba/envs/rag_env/lib/python3.9/site-packages (0.8)\n"
     ]
    }
   ],
   "source": [
    "!pip install docx2txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import logging\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core import (\n",
    "    SimpleDirectoryReader,\n",
    "    VectorStoreIndex,\n",
    "    StorageContext,\n",
    "    load_index_from_storage,\n",
    ")\n",
    "from llama_index.core.schema import Document\n",
    "\n",
    "from llama_index.core.tools import QueryEngineTool, ToolMetadata\n",
    "from llama_index.core import Settings\n",
    "\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s [%(levelname)s] %(message)s\")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = \"...\"\n",
    "\n",
    "VECTOR_STORAGE_DIR = \"./vector\"\n",
    "DATA_STORAGE_DIR = \"./data\"\n",
    "\n",
    "os.makedirs(DATA_STORAGE_DIR, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/Verbs/(Verbs Practice) Potencia Worksheet 1_Elaine - Shilpi Dey.docx\n",
      "(Verbs Practice) Potencia Worksheet 1_Elaine - Shilpi Dey.docx\n",
      "./data/Verbs/(Verbs) 5 Nitieixan & Deinielle - Jakob Lattanzi.pptx\n",
      "(Verbs) 5 Nitieixan & Deinielle - Jakob Lattanzi.pptx\n",
      "./data/Verbs/(Verbs) 2 To Be - Lara Creyghton.pptx\n",
      "(Verbs) 2 To Be - Lara Creyghton.pptx\n",
      "./data/Verbs/(Verbs) English Class #3 - Danielle Coan.pptx\n",
      "(Verbs) English Class #3 - Danielle Coan.pptx\n",
      "./data/Verbs/(Verbs) - Paridhi Rathi.pptx\n",
      "(Verbs) - Paridhi Rathi.pptx\n",
      "./data/Verbs/(Verbs) Lesson on irregular verbs - Dana.docx\n",
      "(Verbs) Lesson on irregular verbs - Dana.docx\n",
      "./data/Verbs/(Verbs_Citizenship Practice) Potencia Tutoring (1) - Nicole Page.docx\n",
      "(Verbs_Citizenship Practice) Potencia Tutoring (1) - Nicole Page.docx\n",
      "./data/Verbs/(Verbs) 10 Lesson with Nitieixan - Jakob Lattanzi.pptx\n",
      "(Verbs) 10 Lesson with Nitieixan - Jakob Lattanzi.pptx\n",
      "./data/Verbs/(Verb Tenses) Lesson #4   - Adriana Da Gama Henriques.pptx\n",
      "(Verb Tenses) Lesson #4   - Adriana Da Gama Henriques.pptx\n",
      "./data/Verbs/(Verbs) English Class #2 - Danielle Coan.pptx\n",
      "(Verbs) English Class #2 - Danielle Coan.pptx\n",
      "./data/Verbs/(Verbs) Lesson #3 - Adriana Da Gama Henriques.pptx\n",
      "(Verbs) Lesson #3 - Adriana Da Gama Henriques.pptx\n",
      "./data/Verbs/(Verbs) 16 Nitieixan & Deinielle - Jakob Lattanzi.pptx\n",
      "(Verbs) 16 Nitieixan & Deinielle - Jakob Lattanzi.pptx\n",
      "./data/Verbs/(Verbs) Potencia Tutoring - Nicole Page.docx\n",
      "(Verbs) Potencia Tutoring - Nicole Page.docx\n",
      "./data/Verbs/(Verbs) 2_to_be_by Sarah L.pptx.pptx\n",
      "(Verbs) 2_to_be_by Sarah L.pptx.pptx\n",
      "./data/Verbs/(Verbs_Basics) 23 Lesson Nitieixan & Deinielle - Jakob Lattanzi.pptx\n",
      "(Verbs_Basics) 23 Lesson Nitieixan & Deinielle - Jakob Lattanzi.pptx\n",
      "./data/Verbs/(Verbs) lesson #6 11.9.20 -- past simple of irregular verbs  - Moxie Thompson.png\n",
      "(Verbs) lesson #6 11.9.20 -- past simple of irregular verbs  - Moxie Thompson.png\n",
      "./data/Verbs/(Verbs) 1 Nitieixan & Deinielle - Jakob Lattanzi.pptx\n",
      "(Verbs) 1 Nitieixan & Deinielle - Jakob Lattanzi.pptx\n",
      "./data/Verbs/(Verbs_Prepositions) Class 7 - Amber Adelman.pdf\n",
      "(Verbs_Prepositions) Class 7 - Amber Adelman.pdf\n",
      "./data/Verbs/(Verb Tenses) - Paridhi Rathi.pptx\n",
      "(Verb Tenses) - Paridhi Rathi.pptx\n"
     ]
    }
   ],
   "source": [
    "def get_file_names_in_directory(directory_path):\n",
    "    \"\"\"List all files in the directory\"\"\"\n",
    "    file_paths = []\n",
    "    names = []\n",
    "    for dirpath, _, filenames in os.walk(directory_path):\n",
    "        for filename in filenames:\n",
    "            file_paths.append(os.path.join(dirpath, filename))\n",
    "            names.append(filename)\n",
    "    return file_paths, names\n",
    "\n",
    "# Get file paths and file names\n",
    "file_paths, file_names = get_file_names_in_directory(DATA_STORAGE_DIR)\n",
    "for file_path, file_name in zip(file_paths, file_names):\n",
    "    print(file_path)\n",
    "    print(file_name)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility functions for datapreprocessing\n",
    "- load_any_documents\n",
    "- load_pptx_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'llama_index.core.schema.Document'>\n",
      "<class 'llama_index.core.schema.Document'>\n",
      "<class 'llama_index.core.schema.Document'>\n",
      "<class 'llama_index.core.schema.Document'>\n",
      "<class 'llama_index.core.schema.Document'>\n",
      "<class 'llama_index.core.schema.Document'>\n",
      "<class 'llama_index.core.schema.Document'>\n",
      "<class 'llama_index.core.schema.Document'>\n",
      "<class 'llama_index.core.schema.Document'>\n",
      "<class 'llama_index.core.schema.Document'>\n",
      "<class 'llama_index.core.schema.Document'>\n",
      "<class 'llama_index.core.schema.Document'>\n",
      "<class 'llama_index.core.schema.Document'>\n",
      "<class 'llama_index.core.schema.Document'>\n",
      "<class 'llama_index.core.schema.Document'>\n",
      "<class 'llama_index.core.schema.ImageDocument'>\n",
      "<class 'llama_index.core.schema.Document'>\n",
      "<class 'llama_index.core.schema.Document'>\n",
      "<class 'llama_index.core.schema.Document'>\n",
      "<class 'llama_index.core.schema.Document'>\n",
      "<class 'llama_index.core.schema.Document'>\n",
      "<class 'llama_index.core.schema.Document'>\n",
      "<class 'llama_index.core.schema.Document'>\n",
      "<class 'llama_index.core.schema.Document'>\n",
      "<class 'llama_index.core.schema.Document'>\n",
      "<class 'llama_index.core.schema.Document'>\n",
      "<class 'llama_index.core.schema.Document'>\n",
      "<class 'llama_index.core.schema.Document'>\n",
      "<class 'llama_index.core.schema.Document'>\n",
      "<class 'llama_index.core.schema.Document'>\n",
      "<class 'llama_index.core.schema.Document'>\n",
      "<class 'llama_index.core.schema.Document'>\n",
      "<class 'llama_index.core.schema.Document'>\n",
      "<class 'llama_index.core.schema.Document'>\n",
      "<class 'llama_index.core.schema.Document'>\n",
      "<class 'llama_index.core.schema.Document'>\n",
      "<class 'llama_index.core.schema.Document'>\n",
      "<class 'llama_index.core.schema.Document'>\n",
      "<class 'llama_index.core.schema.Document'>\n",
      "<class 'llama_index.core.schema.Document'>\n",
      "<class 'llama_index.core.schema.Document'>\n",
      "<class 'llama_index.core.schema.Document'>\n",
      "<class 'llama_index.core.schema.Document'>\n",
      "<class 'llama_index.core.schema.Document'>\n"
     ]
    }
   ],
   "source": [
    "from pptx import Presentation\n",
    "\n",
    "def load_pptx_text(file_path):\n",
    "    \"\"\"Given a pptx file path, extract all the text from it\"\"\"\n",
    "    pres = Presentation(file_path)\n",
    "    pptx_text = []\n",
    "    for slide in pres.slides:\n",
    "        for shape in slide.shapes:\n",
    "            if shape.has_text_frame:\n",
    "                text_frame = shape.text_frame\n",
    "                for paragraph in text_frame.paragraphs:\n",
    "                    for run in paragraph.runs:\n",
    "                        pptx_text.append(run.text)\n",
    "                        \n",
    "    return pptx_text\n",
    "\n",
    "def load_any_documents(dirpath:str):\n",
    "    \"\"\"Given a directory path, load all the files in it: .pptx, .docx, .txt, .pdf, png\"\"\"\n",
    "    documents = []\n",
    "    for file_name in os.listdir(dirpath):\n",
    "        file_path = os.path.join(dirpath, file_name)\n",
    "        \n",
    "        if file_name.endswith(\".pptx\"):\n",
    "            # handle pptx file\n",
    "            pptx_text = load_pptx_text(file_path)\n",
    "            documents.append(Document(text=\"\\n\".join(pptx_text), doc_id=file_name))\n",
    "        else:\n",
    "            documents += (SimpleDirectoryReader(input_files=[file_path]).load_data())\n",
    "            \n",
    "    return documents\n",
    "\n",
    "\n",
    "# documents = load_any_documents(\"./data/Verbs\")\n",
    "# for doc in documents:\n",
    "#     print(f\"{type(doc)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data \n",
    "- read from desginated directory using SimpleDirectoryReader, returns a list of document objects. \n",
    "- docx, ppt, pdf file formats are all supported\n",
    "\n",
    "## Storage Context\n",
    "- represents the location for both **storing** and **loading** the index data\n",
    "- In this demo, each subdirectory is represented as an index\n",
    "  - We could explore other alternatives. \n",
    "\n",
    "```\n",
    "./vector/Verbs/\n",
    "├── Category1/\n",
    "│   ├── SubcategoryA/\n",
    "│   │   ├── file1.txt\n",
    "│   │   └── file2.txt\n",
    "│   └── SubcategoryB/\n",
    "│       └── file3.txt\n",
    "└── Category2/\n",
    "    └── file4.txt\n",
    "\n",
    "./data/Verbs/\n",
    "├── Category1/\n",
    "│   ├── SubcategoryA/       # Indexes for SubcategoryA files are stored here\n",
    "│   └── SubcategoryB/       # Indexes for SubcategoryB files are stored here\n",
    "└── Category2/              # Indexes for Category2 files are stored here\n",
    "```\n",
    "\n",
    "## Indexing\n",
    "- generates embedding for each document, using designated embedding model. \n",
    "- VectorStoreIndex.from_documents: generate index from document nodes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-08 22:44:31,522 [INFO] Loading all indices.\n",
      "2024-11-08 22:44:31,534 [INFO] Loaded existing index for subdirectory Verbs.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# initialize an index list\n",
    "index_list = []\n",
    "\n",
    "## represent index represent a subdirectory\n",
    "for dirpath, _, file_names in os.walk(DATA_STORAGE_DIR):\n",
    "    if file_names:\n",
    "        relative_path = os.path.relpath(dirpath, DATA_STORAGE_DIR)\n",
    "        storage_dir = os.path.join(VECTOR_STORAGE_DIR, relative_path)\n",
    "        os.makedirs(storage_dir, exist_ok=True)\n",
    "        \n",
    "        try:\n",
    "            storage_context = StorageContext.from_defaults(persist_dir=storage_dir)\n",
    "            index = load_index_from_storage(storage_context)\n",
    "            index_list.append(index)\n",
    "            logger.info(f\"Loaded existing index for subdirectory {relative_path}.\")\n",
    "        except FileNotFoundError:\n",
    "            logger.info(f\"Index for {relative_path} not found. Creating a new index.\")\n",
    "            \n",
    "            # load all document in current subdirectory\n",
    "            documents = load_any_documents(dirpath)\n",
    "            # documents = [{\"id\": doc[\"id\"], \"content\": doc[\"content\"]} for doc in documents]\n",
    "            index = VectorStoreIndex.from_documents(documents)\n",
    "            index.storage_context.persist(storage_dir)\n",
    "            # index = \"Dummy\"\n",
    "            # add each index to index list\n",
    "            index_list.append(index)\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error processing subdirectory {relative_path}: {e}\")     \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query Engine\n",
    "- in the previous code block, we converted all the files in Verbs example directory to index(Embeddings)\n",
    "- Now we can retrieve relevant block using the query engine. \n",
    "- A query engine in the context of information retrieval and language models is a component that processes queries by searching through a collection of data (like a set of documents or a database) and returning the most relevant information. \n",
    "\n",
    "### Retriever\n",
    "- Retrievers are responsible for fetching the most relevant context given a user query (or chat message).\n",
    "\n",
    "### RouterQueryEngine\n",
    "- Routers are modules that take in a user query and a set of \"choices\" (defined by metadata), and returns one or more selected choices.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-08 23:53:41,049 [INFO] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-11-08 23:53:43,222 [INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate a lesson plan for verb past tense by starting with a warm-up activity where students reflect on their previous week's goals and performance. Introduce a list of irregular verbs in the present/past tenses and have students practice writing sentences using the past tense forms of these verbs. Include a grammar topic discussion on irregular verb tenses, focusing on examples like \"I write\" to \"I wrote\" and \"I see\" to \"I saw.\" Incorporate a writing and reading aloud activity using an excerpt from a text to practice reading comprehension and advanced tenses. Conclude the lesson with a citizenship test activity where students write down answers to questions related to the President, Vice President, Cabinet positions, and branches of government. Assign homework that includes adding new words to a vocabulary list, practicing speaking in English, and writing out citizenship questions and answers daily.\n"
     ]
    }
   ],
   "source": [
    "def pretty_print_nodes_with_scores(nodes):\n",
    "    \n",
    "    for node_with_score in nodes:\n",
    "        node = node_with_score.node\n",
    "        score = node_with_score.score\n",
    "    \n",
    "        # Print relevant content (text) and metadata\n",
    "        print(\"Content:\", node.text)\n",
    "        print(\"Relevance Score:\", score)\n",
    "        print(\"Source:\", node.metadata.get(\"source\"))\n",
    "        print(\"Page:\", node.metadata.get(\"page\", \"N/A\"))  # Default to \"N/A\" if no page info\n",
    "        print(\"\\n---\\n\")\n",
    "    \n",
    "# 1. query_engine\n",
    "# Most likely, we would have multiple query engines\n",
    "query_engine = []\n",
    "for index in index_list:\n",
    "    query_engine.append(index.as_query_engine(similarity_top_k=3))\n",
    "\n",
    "# response = query_engine[0].query(\"Help me generate a lesson plan for verb past tense\")\n",
    "\n",
    "# print(response)\n",
    "\n",
    "# 2. retriever\n",
    "# retriever = index_list[0].as_retriever()\n",
    "# nodes = retriever.retrieve(\"What are verb past tense?\")\n",
    "\n",
    "# pretty_print_nodes_with_scores(nodes[:1])\n",
    "\n",
    "# 3. routerQueryEngine, if more than on query Engines are created then we can try this out. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
